{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1rFXP0PDxH_",
        "outputId": "69c19364-94c4-4ec3-c599-3ee5d13f2afe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the downloaded file\n",
        "!unzip -q /content/drive/MyDrive/PlantVillage.zip"
      ],
      "metadata": {
        "id": "hISugDg1Dypp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "import torchvision\n",
        "from collections import OrderedDict\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "from torch.optim import lr_scheduler\n",
        "import copy\n",
        "import json\n",
        "import os\n",
        "from os.path import exists\n",
        "from torch.utils.data import Subset\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtSW2yqODzof",
        "outputId": "04295e0f-1528-4c8d-e28d-b8cf06c7a722"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available!  Training on GPU ...\n",
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Organizing the dataset\n",
        "data_dir = '/content/PlantVillage'\n",
        "train_dir = data_dir + '/train'\n",
        "valid_dir = data_dir + '/val'\n",
        "nThreads = 4\n",
        "batch_size = 32\n",
        "use_gpu = torch.cuda.is_available()\n",
        "\n",
        "import json\n",
        "\n",
        "# Define your transforms for the training and validation sets\n",
        "# Data augmentation and normalization for training\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(30),\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ],
      "metadata": {
        "id": "rkhZI0TjD1Ox"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "included_subdirs = ['Tomato___healthy',\n",
        " 'Tomato___Late_blight',\n",
        " 'Tomato___Septoria_leaf_spot',\n",
        " 'Tomato___Target_Spot',\n",
        " 'Tomato___Spider_mites Two-spotted_spider_mite',\n",
        " 'Tomato___Tomato_Yellow_Leaf_Curl_Virus',\n",
        " 'Tomato___Bacterial_spot',\n",
        " 'Tomato___Early_blight',\n",
        " 'Tomato___Leaf_Mold',\n",
        " 'Tomato___Tomato_mosaic_virus']\n",
        "image_datasets = {}\n",
        "for x in ['train', 'val']:\n",
        "    dir_path = os.path.join(data_dir, x)\n",
        "    included_paths = [os.path.join(dir_path, subdir) for subdir in included_subdirs]\n",
        "    dataset = datasets.ImageFolder(dir_path, transform=data_transforms[x])\n",
        "\n",
        "    # Filter samples and update class indexing\n",
        "    filtered_samples = [\n",
        "        (path, class_idx)\n",
        "        for path, class_idx in dataset.samples\n",
        "        if os.path.dirname(path) in included_paths\n",
        "    ]\n",
        "    if len(filtered_samples) == 0:\n",
        "        raise ValueError(f\"No samples found in the included subdirectories for '{x}' split.\")\n",
        "\n",
        "    filtered_paths, filtered_targets = zip(*filtered_samples)\n",
        "    unique_targets = sorted(set(filtered_targets))\n",
        "    target_mapping = {class_idx: i for i, class_idx in enumerate(unique_targets)}\n",
        "\n",
        "    filtered_targets = [target_mapping[class_idx] for class_idx in filtered_targets]\n",
        "    dataset.samples = list(zip(filtered_paths, filtered_targets))\n",
        "    dataset.targets = filtered_targets\n",
        "    dataset.classes = [dataset.classes[class_idx] for class_idx in unique_targets]\n",
        "\n",
        "    image_datasets[x] = dataset\n",
        "\n",
        "# Using the image datasets and the trainforms, define the dataloaders\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
        "                                             shuffle=True, num_workers=2)\n",
        "              for x in ['train', 'val']}\n",
        "\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "\n",
        "class_names = image_datasets['train'].classes"
      ],
      "metadata": {
        "id": "aoStteRbD2xy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_sizes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Or1KlHYsD4nY",
        "outputId": "e8040fb1-be09-4f75-cb32-4a6705033baf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': 14529, 'val': 3631}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('facebookresearch/deit:main', 'deit_tiny_patch16_224', pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Le43mNTh6ngn",
        "outputId": "ae07c786-5101-4407-d848-a513c4141d0b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_deit_main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters(): #freeze model\n",
        "    param.requires_grad = False\n",
        "\n",
        "n_inputs = model.head.in_features\n",
        "model.head = nn.Sequential(\n",
        "    nn.Linear(n_inputs, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(512, 10)\n",
        ")\n",
        "model = model.to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QtoHKQr7UBB",
        "outputId": "581d3387-abcd-4d9c-9bee-16e44282f773"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VisionTransformer(\n",
            "  (patch_embed): PatchEmbed(\n",
            "    (proj): Conv2d(3, 192, kernel_size=(16, 16), stride=(16, 16))\n",
            "    (norm): Identity()\n",
            "  )\n",
            "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
            "  (patch_drop): Identity()\n",
            "  (norm_pre): Identity()\n",
            "  (blocks): Sequential(\n",
            "    (0): Block(\n",
            "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (1): Block(\n",
            "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (2): Block(\n",
            "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (3): Block(\n",
            "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (4): Block(\n",
            "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (5): Block(\n",
            "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (6): Block(\n",
            "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (7): Block(\n",
            "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (8): Block(\n",
            "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (9): Block(\n",
            "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (10): Block(\n",
            "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "    (11): Block(\n",
            "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
            "      (attn): Attention(\n",
            "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
            "        (q_norm): Identity()\n",
            "        (k_norm): Identity()\n",
            "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
            "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls1): Identity()\n",
            "      (drop_path1): Identity()\n",
            "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
            "      (mlp): Mlp(\n",
            "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (drop1): Dropout(p=0.0, inplace=False)\n",
            "        (norm): Identity()\n",
            "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
            "        (drop2): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ls2): Identity()\n",
            "      (drop_path2): Identity()\n",
            "    )\n",
            "  )\n",
            "  (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
            "  (fc_norm): Identity()\n",
            "  (head_drop): Dropout(p=0.0, inplace=False)\n",
            "  (head): Sequential(\n",
            "    (0): Linear(in_features=192, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Now, we import timm, torchvision image models\n",
        "!pip install timm # kaggle doesnt have it installed by default\n",
        "import timm\n",
        "from timm.loss import LabelSmoothingCrossEntropy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozYnlgVk-men",
        "outputId": "a6a24491-620b-4373-f868-f6531e98fb25"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (0.9.2)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.2+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.16.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.22.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = LabelSmoothingCrossEntropy()\n",
        "criterion = criterion.to(device)\n",
        "optimizer = optim.Adam(model.head.parameters(), lr=0.001)\n",
        "# lr scheduler\n",
        "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.97)"
      ],
      "metadata": {
        "id": "0HK12pf47VMg"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=20):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best valid accuracy: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "metadata": {
        "id": "UKPig0L07mf1"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "training_start_time = time.time()\n",
        "model_ft = train_model(model, criterion, optimizer, exp_lr_scheduler)\n",
        "print('Training finished, took {:.2f}s'.format(time.time() - training_start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdOt4_KS7qp5",
        "outputId": "abecff72-67c8-442f-e801-67548f8ad979"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "----------\n",
            "train Loss: 1.1221 Acc: 0.7495\n",
            "val Loss: 0.8853 Acc: 0.8502\n",
            "\n",
            "Epoch 2/20\n",
            "----------\n",
            "train Loss: 0.9337 Acc: 0.8396\n",
            "val Loss: 0.7908 Acc: 0.9132\n",
            "\n",
            "Epoch 3/20\n",
            "----------\n",
            "train Loss: 0.8866 Acc: 0.8592\n",
            "val Loss: 0.7864 Acc: 0.9064\n",
            "\n",
            "Epoch 4/20\n",
            "----------\n",
            "train Loss: 0.8629 Acc: 0.8703\n",
            "val Loss: 0.7678 Acc: 0.9174\n",
            "\n",
            "Epoch 5/20\n",
            "----------\n",
            "train Loss: 0.8448 Acc: 0.8820\n",
            "val Loss: 0.7715 Acc: 0.9171\n",
            "\n",
            "Epoch 6/20\n",
            "----------\n",
            "train Loss: 0.8419 Acc: 0.8816\n",
            "val Loss: 0.7514 Acc: 0.9284\n",
            "\n",
            "Epoch 7/20\n",
            "----------\n",
            "train Loss: 0.8405 Acc: 0.8811\n",
            "val Loss: 0.7561 Acc: 0.9223\n",
            "\n",
            "Epoch 8/20\n",
            "----------\n",
            "train Loss: 0.8291 Acc: 0.8868\n",
            "val Loss: 0.7330 Acc: 0.9323\n",
            "\n",
            "Epoch 9/20\n",
            "----------\n",
            "train Loss: 0.8194 Acc: 0.8928\n",
            "val Loss: 0.7608 Acc: 0.9221\n",
            "\n",
            "Epoch 10/20\n",
            "----------\n",
            "train Loss: 0.8239 Acc: 0.8917\n",
            "val Loss: 0.7293 Acc: 0.9331\n",
            "\n",
            "Epoch 11/20\n",
            "----------\n",
            "train Loss: 0.8107 Acc: 0.8977\n",
            "val Loss: 0.7304 Acc: 0.9295\n",
            "\n",
            "Epoch 12/20\n",
            "----------\n",
            "train Loss: 0.8117 Acc: 0.8981\n",
            "val Loss: 0.7340 Acc: 0.9331\n",
            "\n",
            "Epoch 13/20\n",
            "----------\n",
            "train Loss: 0.8087 Acc: 0.8965\n",
            "val Loss: 0.7217 Acc: 0.9364\n",
            "\n",
            "Epoch 14/20\n",
            "----------\n",
            "train Loss: 0.8036 Acc: 0.9008\n",
            "val Loss: 0.7221 Acc: 0.9347\n",
            "\n",
            "Epoch 15/20\n",
            "----------\n",
            "train Loss: 0.7905 Acc: 0.9038\n",
            "val Loss: 0.7275 Acc: 0.9380\n",
            "\n",
            "Epoch 16/20\n",
            "----------\n",
            "train Loss: 0.8016 Acc: 0.8999\n",
            "val Loss: 0.7140 Acc: 0.9405\n",
            "\n",
            "Epoch 17/20\n",
            "----------\n",
            "train Loss: 0.7997 Acc: 0.9009\n",
            "val Loss: 0.7132 Acc: 0.9419\n",
            "\n",
            "Epoch 18/20\n",
            "----------\n",
            "train Loss: 0.8013 Acc: 0.9011\n",
            "val Loss: 0.7095 Acc: 0.9444\n",
            "\n",
            "Epoch 19/20\n",
            "----------\n",
            "train Loss: 0.7968 Acc: 0.9034\n",
            "val Loss: 0.7112 Acc: 0.9422\n",
            "\n",
            "Epoch 20/20\n",
            "----------\n",
            "train Loss: 0.7885 Acc: 0.9079\n",
            "val Loss: 0.7056 Acc: 0.9405\n",
            "\n",
            "Training complete in 19m 43s\n",
            "Best valid accuracy: 0.944368\n",
            "Training finished, took 1183.16s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Size and number of parameters of model\n",
        "param_size = 0\n",
        "num_parameters = 0\n",
        "for param in model.parameters():\n",
        "    num_parameters += 1\n",
        "    param_size += param.nelement() * param.element_size()\n",
        "buffer_size = 0\n",
        "for buffer in model.buffers():\n",
        "    buffer_size += buffer.nelement() * buffer.element_size()\n",
        "\n",
        "size_all_mb = (param_size + buffer_size) / 1024**2\n",
        "print('model size: {:.3f}MB'.format(size_all_mb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sar6GwRQEZyX",
        "outputId": "38cbb2ae-e7d4-487c-d52c-915957880071"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model size: 21.470MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(num_parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIfbefAQEPLv",
        "outputId": "8238e246-3fdb-4acb-8a7a-7d466a889c73"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "154\n"
          ]
        }
      ]
    }
  ]
}